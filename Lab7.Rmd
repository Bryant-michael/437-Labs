---
title: 'Lab Assignment #7'
author: "Vanessa Avilez, Michael Bryant, Phuong Traceyle"
date: "Due March 24, 2023"
output: html_document
---

# Instructions

The purpose of this lab is to introduce several different classification strategies and variations on classification accuracy. In this lab we will work with another staple set of strategies: Naive Bayes and linear/quadratic discriminant analysis.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries and data, message = FALSE, warning = FALSE}
library(ISLR2)
library(ggplot2)
library(dplyr)
library(nycflights13)
library(e1071) # Naive Bayes
library(MASS) # LDA/QDA
library(yardstick) # only tidymodels package we'll need in this lab
```

This lab assignment is worth a total of **25 points**.

# Problem 1: Naive Bayes

## Part a (Code: 1 pt)

Run the code in ISLR Lab 4.7.5.

```{r attaching smarket, message = FALSE, warning = FALSE}
library (e1071)
attach(Smarket)
```


```{r 7.5 p1}
train <- (Smarket$Year < 2005)
Smarket.2005 <- Smarket[!train , ]
Direction.2005 <- Direction[!train]

nb.fit <- naiveBayes(Direction ~ Lag1 + Lag2 , data = Smarket , subset = train)

nb.fit
```

```{r 7.5 p2 mean/sd}
mean(Lag1[train][Direction[train] == "Down"])
sd(Lag1[train][Direction[train] == "Down"])
```

```{r 7.5 p3 predict}
nb.class <- predict (nb.fit, Smarket.2005)
table(nb.class, Direction.2005)
mean(nb.class == Direction.2005)
```

```{r 7.5 p4}
nb.preds <- predict (nb.fit , Smarket.2005, type = "raw")
nb.preds[1:5, ]
```


## Part b (Code: 1 pt)

Recall that in Lab 6 we filtered the flights to only the United, American, and Delta carriers. Here we add another variable, `arr_ontime`, to represent whether the flight arrived on time or not.

```{r filter flights}
flights2 <- flights %>% filter(
  carrier %in% c("UA", "AA", "DL"),
  !is.na(dep_delay),
  !is.na(arr_delay)
) %>%
  mutate(
    arr_ontime = as.factor(if_else(arr_delay <= 0, "yes", "no"))
  )
```

Non-randomly divide the `flights2` dataset into `flights_training`, which contains all flights through October, and `flights_test`, which contains all flights in November and December. You should be able to use the `filter` function to do this.

Then, fit a Naive Bayes model on the training set predicting whether a flight will be delayed (`arr_ontime` = "no") based on the departure delay (`dep_delay`), `carrier`, `distance` traveled, and `origin`.

```{r flights training and test}
train <- (flights2$month < 11) #train from January to october
flights_training <- flights2[train, ]
flights_test <- flights2[!train,]
```

```{r flights nb fit}
flights_nb <- naiveBayes(arr_ontime ~ dep_delay + carrier + distance + origin, data = flights_training)

flights_nb
```

## Part c (Code: 1.5 pts)

Unfortunately, there is no easy way to use `augment` on this model, so we'll have to make the predictions ourselves.

First, make class predictions on the `flights_test` dataset using similar code to that done in Lab 4.7.5. Then, create the `flights_nb_predictions` data frame or tibble containing two columns: `predicted`, representing the predicted classes, and `actual`, representing the actual classes. Use `flights_nb_predictions` to obtain the confusion matrix for the model.
```{r flights nb predict}
#flights_nb_pred_probs <- predict(flights_nb, newdata = flights_test, type = "raw")
flights_nb_pred_class <- predict(flights_nb, newdata = flights_test, type = "class")

flights_nb_predictions <- data.frame(predicted = flights_nb_pred_class,
                               actual = flights_test$arr_ontime )

confusion_flightsnb <- conf_mat(flights_nb_predictions, truth = actual, estimate = predicted)

confusion_flightsnb

```

## Part d (Code: 0.5 pts; Explanation: 2 pts)

Without running any additional code, use the confusion matrix from part (c) to estimate the sensitivity, specificity, positive predictive value, and negative predictive value for the model. Express all answers as fractions and then convert to decimals rounded to the thousandths place (3 decimal places). 

sensitivity = 3957/ 9249 = 0.428
specificity = 12961 / 13449 = 0.964
positive predictive value = 3957 / 4445 = 0.890
negative predictive value = 12961 / 18253 = 0.710

Then, using the `summary` function on your confusion matrix, check your answers. Remember that we are trying to predict that a flight will be delayed (`arr_ontime` = "no").

```{r fligts confusion matrix summary}
summary(confusion_flightsnb)
```

The proportions from the confusion table match the estimates from the summary. 

# Problem 2: Discriminant Analysis

## Part a (Code: 1 pt)

```{r 4.7.1 p3, warning=FALSE, message=FALSE}
attach(Smarket)
```

```{r 4.7.2 p6}
train.islr <- (Year < 2005)
Smarket.2005 <- Smarket[!train,]
Direction.2005 <- Direction[!train]
```

Run the code in ISLR Lab 4.7.3.
```{r 4.7.3.a}
library (MASS)
train <- (Year < 2005)
lda.fit <- lda(Direction ~ Lag1 + Lag2 , data = Smarket , subset = train.islr)
lda.fit
plot (lda.fit)
```

```{r 4.7.3.b}
lda.pred <- predict (lda.fit , Smarket.2005)
names (lda.pred)
```

```{r 4.7.3.c}
lda.class <- lda.pred$class
table (lda.class, Direction.2005)
mean (lda.class == Direction.2005)
```

```{r 4.7.3.d}
sum (lda.pred$posterior[, 1] >= .5)
sum (lda.pred$posterior[, 1] < .5)
```

```{r 4.7.3.e}
lda.pred$posterior[1:20, 1]
lda.class[1:20]
```

```{r 4.7.3.f}
sum (lda.pred$posterior[, 1] > .9)
```

## Part b (Code: 1 pt)

Run the code in ISLR Lab 4.7.4.

```{r 4.7.4 p1}
qda.fit <- qda(Direction ~ Lag1 + Lag2 , data = Smarket ,
subset = train)
qda.fit
```

```{r 4.7.4 p2}
qda.class <- predict(qda.fit , Smarket.2005)$class
table(qda.class , Direction.2005)
mean(qda.class == Direction.2005)
```

## Part c (Code: 1 pt)

Fit a LDA model on the training set predicting whether a flight will be delayed (`arr_ontime` = "no") based on the departure delay (`dep_delay`), `carrier`, `distance` traveled, and `origin`.

```{r 2c}
lda.fit <- lda(arr_ontime ~ dep_delay + carrier + distance + origin , data = flights2 , subset = train)
```


## Part d (Code: 1.5 pts)

Unfortunately, there is no easy way to use `augment` on this model, so we'll have to make the predictions ourselves.

First, make class predictions on the `flights_test` dataset using similar code to that done in Lab 4.7.3. Then, create the `flights_lda_predictions` data frame or tibble containing two columns: `predicted`, representing the predicted classes, and `actual`, representing the actual classes. Use `flights_lda_predictions` to obtain the confusion matrix for the model.

```{r 2d}
lda.pred.f <- predict (lda.fit , flights_test)
lda.class.f <- lda.pred.f$class
flights_lda_predictions <- data.frame(predicted = lda.class.f, actual = flights_test$arr_ontime)
table(flights_lda_predictions)
```


## Part e (Code: 0.5 pts; Explanation: 2 pts)

Without running any additional code, use the confusion matrix from part (d) to estimate the sensitivity, specificity, positive predictive value, and negative predictive value for the model. Express all answers as fractions and then convert to decimals rounded to the thousandths place (3 decimal places). 

Then, using the `summary` function on your confusion matrix, check your answers. Remember that we are trying to predict that a flight will be delayed (`arr_ontime` = "no").

Sensitivity: 2201/(2201 + 7048) = 0.238
Specificity: 13414/(35 + 13414) = 0.997
Positive predictive value: 2201 + 35 = 2236
Negative predictive value: 7048 + 13414 = 20462

```{r 2e}
summary(flights_lda_predictions)
```


## Part f (Code: 3 pts; Explanation: 2 pts)

Repeat parts (c) through (e) for the QDA model. (Obviously, call your new data frame/tibble `flights_qda_predictions` instead.)

```{r 2f (c)}
qda.fit <- qda(arr_ontime ~ dep_delay + carrier + distance + origin , data = flights2 , subset = train)
```

```{r 2f (d)}
qda.pred.f <- predict (qda.fit , flights_test)
qda.class.f <- qda.pred.f$class
flights_qda_predictions <- data.frame(predicted = qda.class.f, actual = flights_test$arr_ontime)
table(flights_qda_predictions)
```

Sensitivity: 4079/(4079 + 5170) = 0.441
Specificity: 12959/(12959 + 490) = 0.964
TPV: 4079 + 490 = 4569
NPV: 5170 + 12959 = 18129

```{r 2e}
summary(flights_qda_predictions)
```

# Problem 3: Model Selection

## Part a (Code: 2 pts)

Add a column to the `flights_nb_predictions`, `flights_lda_predictions`, and `flights_qda_predictions` indicating the probability of not arriving on time (`arr_ontime == "no"`). It may be easiest to first obtain the predicted probabilities of being in each class, then add the column to the relevant data frame using `cbind` or `mutate`.

Then, compute the Brier scores for each model. As shown in the class activity, it is easiest to use the `mutate` function to obtain the "squared error" for each observation and then average the squared error.

```{r flights adding predicetd column nb}
flights_nb_pred_probs <- predict(flights_nb, newdata = flights_test, type = "raw")
flights_nb_predictions2 <- data.frame(prediction = flights_nb_predictions, probs = flights_nb_pred_probs[,1])

#View(flights_nb_predictions2)
```

```{r flights adding predicetd column lda}
flights_lda_pred_probs <- lda.pred.f$posterior[,1]
flights_lda_predictions2 <- cbind(flights_lda_predictions, flights_lda_pred_probs)

#View(flights_lda_predictions2)
```

```{r flights adding predicetd column qda}
flights_qda_pred_probs <- qda.pred.f$posterior[,1]
flights_qda_predictions2 <- cbind(flights_qda_predictions, flights_qda_pred_probs)

#View(flights_qda_predictions2)
```

```{r computing brier scores}
brier_nb <- flights_nb_predictions2 %>% mutate(
  squared_error = case_when(
    prediction.predicted == "no" ~ (1 - probs)^2,
    prediction.predicted == "yes" ~ (probs)^2
  )
)
mean(brier_nb$squared_error)

brier_lda <- flights_lda_predictions2 %>% mutate(
  squared_error = case_when(
    predicted == "no" ~ (1 - flights_lda_pred_probs)^2,
    predicted == "yes" ~ (flights_lda_pred_probs)^2
  )
)
mean(brier_lda$squared_error)

brier_qda <- flights_qda_predictions2 %>% mutate(
  squared_error = case_when(
    predicted == "no" ~ (1 - flights_qda_pred_probs)^2,
    predicted == "yes" ~ (flights_qda_pred_probs)^2
  )
)
mean(brier_qda$squared_error)
```


## Part b (Code: 1 pt)

Using the `mn_log_loss` function, obtain the cross-entropy/log loss for each of the three models.

```{r log_loss}
mn_log_loss(flights_nb_predictions2,
            truth = prediction.actual,
            probs,
            event_level = "first"
)

mn_log_loss(flights_lda_predictions2,
            truth = actual,
            flights_lda_pred_probs,
            event_level = "first"
)

mn_log_loss(flights_qda_predictions2,
            truth = actual,
            flights_qda_pred_probs,
            event_level = "first"
)

```


## Part c (Code: 1 pt)

Using the `mcc` function, obtain the Matthews Correlation Coefficient for each of the three models. 

```{r mcc}
mcc(flights_nb_predictions2, truth = prediction.actual, estimate = flights_nb_predictions2[,1])
mcc(flights_lda_predictions2, truth = actual, estimate = flights_lda_predictions2[,1])
mcc(flights_qda_predictions2, truth = actual, estimate = flights_qda_predictions2[,1])
```


## Part d (Explanation: 1.5 pts)

Compare the Brier score, log loss, and Matthews correlation coefficient for the three models by filling in the table below. Round all numbers to 3 decimal places.

| Model | Brier | log loss | MCC |
|:---:|---:|---:|---:|
| NB  | 0.011 | 0.774 | 0.485 |
| LDA | 0.0863 | 0.586 | 0.388 |
| QDA | 0.012 |  0.724 | 0.496	 |

Which of the three models performs the best on this test set by each measure?

brier: Naive Bayes did the best
Log loss: LDA did the best
MCC: LDA did the best

## Part e (Explanation: 1.5 pts)

If you had to recommend one of the three models to use to predict whether a flight would be delayed, would you use the Naive Bayes, LDA, or QDA model? Explain.

We recommend LDA because it has a lower log-loss and MCC, so it is more accurate and is more confident in each prediction.
